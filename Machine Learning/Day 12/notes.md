# Day 12 – Machine Learning  

###  What I Learned Today  
- Continued with **Multivariable Regression**  
- Explored how multiple features affect predictions simultaneously  
- Understood the role of **feature scaling** and **matrix representation** in regression  

---

###  Topics Covered  
1. Basics of **Multivariable Regression** – extending simple linear regression to multiple inputs  
2. Importance of **Normal Equation** and **Gradient Descent** for multivariable case  
3. Concept of **feature scaling** to improve convergence speed  

---

###  Reflection  
- Learned that moving from single-variable to multivariable regression makes models **more practical**  
- Understood why **feature scaling** is crucial for efficient optimization  
- This sets the foundation for applying regression to **real-world datasets with many features**  
